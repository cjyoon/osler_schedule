install.packages("shiny")
library(shiny)
ui <- fluidPage(
"hello world!"
)
server <- function(input, output, session){
}
shinyApp(ui, server)
library(lobstr)
install.packages('lobstr')
df <- data.frame(runif(3), runif(3))
df
names(df) = c(1,2)
df
df$1
df$`1`
x <- c(1,2,3)
cat(tracemem(x), '\n')
?tracemem
cat(tracemem(x))
y<-x
y[[3]] <- 5L
y
y[2] <- 3
y
libary(tidyverse)
library(tidyverse)
directory <- "Dropbox/Osler/"
# List all .tsv files in the directory
file_list <- list.files(path = directory, pattern = "\\.tsv$", full.names = TRUE)
# Read each .tsv file into a list of data frames
data_list <- lapply(file_list, read.delim)
file_list
data_list
directory <- "Dropbox/Osler/"
file_list
directory <- "Dropbox/Osler/"
# List all .tsv files in the directory
file_list <- list.files(path = directory, pattern = "\\.tsv$", full.names = TRUE)
file_list
length(file_list)
# List all .tsv files in the directory
file_list <- list.files(path = directory, pattern = "\\.tsv$", full.names = TRUE)
file_list
# Read each .tsv file into a list of data frames
data_list <- lapply(file_list, read.delim)
data_list
dim(data_list)
# Combine all data frames into one (optional)
combined_data <- bind_rows(data_list)
combined_data
print(data_list)
names(data_list)
# Combine all data frames into one (optional)
combined_data <- bind_rows(data_list)
# Convert columns to consistent types
data_list <- lapply(data_list, function(df) {
# Example: Ensure 'name' column is character
if ("name" %in% colnames(df)) {
df$name <- as.character(df$name)
}
# Add more conversions if needed
return(df)
})
# Combine all data frames into one
combined_data <- bind_rows(data_list)
data_list[[1]]
# Read each .tsv file into a list of data frames
data_list <- lapply(file_list, read_delim)
# Convert columns to consistent types
data_list <- lapply(data_list, function(df) {
# Example: Ensure 'name' column is character
if ("name" %in% colnames(df)) {
df$name <- as.character(df$name)
}
# Add more conversions if needed
return(df)
})
# Combine all data frames into one
combined_data <- bind_rows(data_list)
combined_data
combined_data %>% filter(date == '09-06-2024')
combined_data  %>% spread(date)
combined_data  %>% spread(date, name)
new_table = combined_data  %>% spread(date, name)
combined_data %>% filter(name=='Yoon_Christopher')
new_table = combined_data  %>% filter(name=='Yoon_Christopher') %>% spread(date, name)
new_table
new_table = combined_data  %>% filter(name=='Yoon_Christopher') %>% spread(date, schedule)
combined_data
ombined_data  %>% filter(name=='Yoon_Christopher')
?spread
new_table = combined_data  %>% filter(name=='Yoon_Christopher') %>% spread(date, schedule, name)
new_table = combined_data  %>% filter(name=='Yoon_Christopher') %>%   pivot_longer(
cols = !date,
names_to = "name",
values_to = "schedule"
)
new_table
new_table = combined_data  %>% filter(name=='Yoon_Christopher') %>%   pivot_wider(
names_from = "date"
names_prefix = ""
new_table = combined_data  %>% filter(name=='Yoon_Christopher') %>%   pivot_wider(
names_from = "date",
names_prefix = "",
values_from = "schedule"
)
new_table
View(new_table)
?pivot_wider
new_table = combined_data  %>% filter(name=='Yoon_Christopher') %>%   pivot_wider(
names_from = "date",
names_prefix = "",
values_from = "schedule",
values_fn = list(value = ~ paste(., collapse = "/"))  # Combine duplicates into a comma-separated string
)
View(new_table)
new_table = combined_data  %>% filter(name=='Yoon_Christopher') %>%   pivot_wider(
names_from = "date",
names_prefix = "",
values_from = "schedule",
values_fn = list(schedule = ~ paste(., collapse = "/"))  # Combine duplicates into a comma-separated string
)
View(new_table)
new_table = combined_data  %>% pivot_wider(
names_from = "date",
names_prefix = "",
values_from = "schedule",
values_fn = list(schedule = ~ paste(., collapse = "/"))  # Combine duplicates into a comma-separated string
)
new_table
View(new_table)
dim(new_table)
combined_data %>% select(date) %>% unique
dim(new_table)
library(tidyverse)
directory <- "Dropbox/Osler/"
# List all .tsv files in the directory
file_list <- list.files(path = directory, pattern = "\\.tsv$", full.names = TRUE)
# Read each .tsv file into a list of data frames
data_list <- lapply(file_list, read_delim)
# Convert columns to consistent types
data_list <- lapply(data_list, function(df) {
# Example: Ensure 'name' column is character
if ("name" %in% colnames(df)) {
df$name <- as.character(df$name)
}
# Add more conversions if needed
return(df)
})
# Combine all data frames into one
combined_data <- bind_rows(data_list)
# Print the combined data frame
print(combined_data)
new_table = combined_data  %>% pivot_wider(
names_from = "date",
names_prefix = "",
values_from = "schedule",
values_fn = list(schedule = ~ paste(., collapse = "/"))  # Combine duplicates into a comma-separated string
)
View(new_table)
library(shiny)
install.packages("reactable")
library(reactable)
ui <- fluidPage(
reactableOutput("table")
)
server <- function(input, output) {
output$table <- renderReactable({
reactable(new_table)
})
}
shinyApp(ui, server)
install.packages("DT")  # Install DT package
library(DT)
datatable(new_table,
options = list(pageLength = 10,  # Number of rows per page
autoWidth = TRUE,  # Auto-adjust column widths
scrollX = TRUE      # Enable horizontal scrolling
),
rownames = FALSE  # Do not show row names
)
datatable(new_table,
options = list(
pageLength = 10,         # Number of rows per page
autoWidth = TRUE,        # Auto-adjust column widths
scrollX = TRUE,          # Enable horizontal scrolling
columnDefs = list(
list(className = 'dt-center', targets = "_all")  # Center align all columns
),
initComplete = JS(
"function(settings, json) {",
"  var todayDate = '", today_date_char, "';",
"  var columnIndex = $(this.api().columns().header()).toArray().findIndex(function(header) {",
"    return $(header).text().trim() === todayDate;",
"  });",
"  if (columnIndex !== -1) {",
"    var table = $(this.api().table().node());",
"    table.scrollLeft(table.find('th').eq(columnIndex).position().left);",
"  }",
"}"
)
),
rownames = FALSE  # Do not show row names
)
datatable(newtable,
options = list(
pageLength = 10,
autoWidth = TRUE,
scrollX = TRUE,
columnDefs = list(
list(className = 'dt-center', targets = "_all")
),
initComplete = JS(
"function(settings, json) {",
"  var todayDate = '", today_date_char, "';",
"  var columnIndex = $(this.api().columns().header()).toArray().findIndex(function(header) {",
"    return $(header).text().trim() === todayDate;",
"  });",
"  if (columnIndex !== -1) {",
"    var table = $(this.api().table().node());",
"    var ths = table.find('th');",
"    var offset = ths.eq(columnIndex).offset().left;",
"    table.scrollLeft(offset);",
"  }",
"}"
)
),
rownames = FALSE
)
# Define server logic
reactable(data, searchable = TRUE, minRows = 10)
# Define server logic
reactable(newtable, searchable = TRUE, minRows = 10)
)install.packages('rsconnect')
install.packages('rsconnect')
library(rsconnect)
library(DT)
rsconnect::deployApp('Dropbox/Osler/osler_schedule.R')
rsconnect::deployApp('Dropbox/Osler/Scheduler')
rsconnect::setAccountInfo(name='cyoon14',
token='773EBAD1D531698A8B9BB0CC651EC109',
secret='cwUWIrEHyC6EULoGBaDwMz69pM6fw/50Bq5QrNww')
rsconnect::deployApp('Dropbox/Osler/Scheduler')
directory <- "Dropbox/Osler/Scheduler/"
# List all .tsv files in the directory
file_list <- list.files(path = directory, pattern = "\\.tsv$", full.names = TRUE)
# Read each .tsv file into a list of data frames
data_list <- lapply(file_list, read_delim)
# Convert columns to consistent types
data_list <- lapply(data_list, function(df) {
# Example: Ensure 'name' column is character
if ("name" %in% colnames(df)) {
df$name <- as.character(df$name)
}
# Add more conversions if needed
return(df)
})
# Combine all data frames into one
combined_data <- bind_rows(data_list)
# Print the combined data frame
print(combined_data)
new_table = combined_data  %>% pivot_wider(
names_from = "date",
names_prefix = "",
values_from = "schedule",
values_fn = list(schedule = ~ paste(., collapse = "/"))  # Combine duplicates into a comma-separated string
)
datatable(new_table, options = list(pageLength = 5, autoWidth = TRUE))
# Define UI
ui <- fluidPage(
titlePanel("Osler Intern Schedule"),
sidebarLayout(
sidebarPanel(
# You can add input controls here if needed
),
mainPanel(
DTOutput("table")
)
)
)
# Define server logic
server <- function(input, output) {
# Render the interactive table
output$table <- renderDT({
datatable(new_table, options = list(pageLength = 5, autoWidth = TRUE))
})
}
# Run the application
shinyApp(ui = ui, server = server)
# Define server logic
server <- function(input, output) {
# Render the interactive table
output$table <- renderDT({
datatable(new_table, options = list(pageLength = 100, autoWidth = TRUE))
})
}
# Run the application
shinyApp(ui = ui, server = server)
rsconnect::setAccountInfo(name='cyoon14',
token='773EBAD1D531698A8B9BB0CC651EC109',
secret='cwUWIrEHyC6EULoGBaDwMz69pM6fw/50Bq5QrNww')
rsconnect::deployApp('Dropbox/Osler/Scheduler')
sessionInfo()
library(tidyverse)
library(rsconnect)
library(DT)
library(shiny)
#
# time zone set to nyc
Sys.setenv(TZ = "America/New_York")
#
#
setwd("~/Dropbox/Osler/Osler_shiny")
#creating a single table, commmented out for faster loading
# # # List all .tsv files in the directory
intern_file_list <- list.files('intern_schedule/', pattern = "\\.tsv$", full.names = TRUE)
jarsar_file_list <- list.files('jar_sar_schedule/', pattern = "\\.tsv$", full.names = TRUE)
jarsar_file_list2 <- list.files('jarsar2025/schedule//', pattern = "\\.tsv$", full.names = TRUE)
# Read each .tsv file into a list of data frames
data_list <- lapply(c(intern_file_list, jarsar_file_list, jarsar_file_list2), read_delim)
# Convert columns to consistent types
data_list <- lapply(data_list, function(df) {
# Example: Ensure 'name' column is character
if ("name" %in% colnames(df)) {
df$name <- as.character(df$name)
}
# Add more conversions if needed
return(df)
})
# Combine all data frames into one
combined_data <- bind_rows(data_list)
# Print the combined data frame
print(combined_data)
new_table = combined_data  %>% pivot_wider(
names_from = "date",
names_prefix = "",
values_from = "schedule",
values_fn = list(schedule = ~ paste(., collapse = "/"))  # Combine duplicates into a comma-separated string
)
add_asterisk <- function(vec) {
# Apply the condition to each element in the vector
vec <- ifelse(grepl("OPH|ED", vec), paste0(".", vec), vec)
return(vec)
}
new_table$name = add_asterisk(new_table$name)
# Create a logical vector to separate alphabetic from non-alphabetic starting names
is_alpha <- grepl("^[A-Za-z]", new_table$name)
new_table <- new_table[order(!is_alpha, new_table$name), ]
#
#
write_delim(new_table, file='~/Dropbox/Osler/Osler_shiny/osler_schedule_table.tsv', delim='\t')
runApp()
jarsar_block_table2 = remove_unnamed_columns(read_delim('block_schedule/jar_sar_block_view2025.tsv', delim='\t'))
find_block <- function(input_date, block_table) {
# Extract column names
col_names <- colnames(block_table)
# Create a data frame to store block names and date ranges
blocks <- data.frame(Block = character(), Start = as.Date(character()), End = as.Date(character()), stringsAsFactors = FALSE)
# Regular expression to extract block names and date ranges
pattern <- "(.+?)\\s(\\d{1,2}/\\d{1,2}/\\d{2})-(\\d{1,2}/\\d{1,2}/\\d{2})"
for (col in col_names) {
matches <- regmatches(col, regexec(pattern, col))
if (length(matches[[1]]) == 4) {
block_name <- matches[[1]][2]
start_date <- as.Date(matches[[1]][3], format="%m/%d/%y")
end_date <- as.Date(matches[[1]][4], format="%m/%d/%y")
# Append to blocks data frame
blocks <- rbind(blocks, data.frame(Block = block_name, Start = start_date, End = end_date, stringsAsFactors = FALSE))
}
}
# Convert input_date to Date format
input_date <- as.Date(input_date, format="%Y-%m-%d")
# Find the corresponding block
matching_block <- blocks$Block[input_date >= blocks$Start & input_date <= blocks$End]
# Return the block name or NA if not found
if (length(matching_block) == 0) {
return('1A')
} else {
return(matching_block)
}
}
# Function to filter blocks and return the subset
filter_blocks <- function(block_id, block_table) {
col_names <- colnames(block_table)
# Find the index of the given block_id
match_index <- which(grepl(paste0("^", block_id, " "), col_names))
# If block_id is found, subset the table
if (length(match_index) > 0) {
return(block_table[, c(1, match_index:ncol(block_table))])  # Keep 'name' column
} else {
return(block_table)  # Return full table if block_id is not found
}
}
remove_unnamed_columns <- function(df) {
df <- df[, !grepl("^Unnamed", colnames(df))]
df = df %>% filter(!is.na(name))
return(df)
}
new_table = read_delim('osler_schedule_table.tsv', delim='\t')
intern_block_table = remove_unnamed_columns(read_delim('block_schedule/intern_block_view.tsv', delim='\t'))
jarsar_block_table = remove_unnamed_columns(read_delim('block_schedule/jar_sar_block_view.tsv', delim='\t'))
jarsar_block_table2 = remove_unnamed_columns(read_delim('block_schedule/jar_sar_block_view2025.tsv', delim='\t'))
jarsar_block_table2 = remove_unnamed_columns(read_delim('block_schedule/block_view_jarsar2025.tsv', delim='\t'))
head(jarsar_block_table2)
head(jarsar_block_table)
jarsar_block_table = jarsar_block_table %>% full_join(by=name, jarsar_block_table2)
jarsar_block_table = jarsar_block_table %>% full_join(by='name', jarsar_block_table2)
?full_join
jarsar_block_table = jarsar_block_table %>% full_join(jarsar_block_table2, by='name')
colnames(jarsar_block_table)
intern_block_table = remove_unnamed_columns(read_delim('block_schedule/intern_block_view.tsv', delim='\t'))
jarsar_block_table = remove_unnamed_columns(read_delim('block_schedule/jar_sar_block_view.tsv', delim='\t'))
jarsar_block_table2 = remove_unnamed_columns(read_delim('block_schedule/block_view_jarsar2025.tsv', delim='\t'))
jarsar_block_table = jarsar_block_table %>% full_join(jarsar_block_table2, by='name')
colnames(intern_block_table)
colnames(jarsar_block_table)
colnames(jarsar_block_table2)
View(intern_block_table)
View(jarsar_block_table)
intern_block_table = remove_unnamed_columns(read_delim('block_schedule/intern_block_view.tsv', delim='\t'))
jarsar_block_table = remove_unnamed_columns(read_delim('block_schedule/jar_sar_block_view.tsv', delim='\t'))
intern_block_table = remove_unnamed_columns(read_delim('block_schedule/intern_block_view.tsv', delim='\t'))
jarsar_block_table = remove_unnamed_columns(read_delim('block_schedule/jar_sar_block_view.tsv', delim='\t'))
jarsar_block_table2 = remove_unnamed_columns(read_delim('block_schedule/block_view_jarsar2025.tsv', delim='\t'))
jarsar_block_table = remove_unnamed_columns(read_delim('block_schedule/jar_sar_block_view.tsv', delim='\t'))
